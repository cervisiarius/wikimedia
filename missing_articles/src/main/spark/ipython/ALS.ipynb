{
 "metadata": {
  "name": "",
  "signature": "sha256:ee2869ff3fc2bc302ae006f297783ec54dad259454aa76118a0ec2ec4d155088"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.sql import *\n",
      "from operator import add\n",
      "sqlContext = SQLContext(sc)\n",
      "import csv\n",
      "import StringIO\n",
      "import matplotlib.pyplot as plt \n",
      "from pyspark.mllib.recommendation import ALS, Rating\n",
      "from random import randint\n",
      "import sys\n",
      "import itertools\n",
      "from math import sqrt\n",
      "from operator import add\n",
      "from os.path import join, isfile, dirname\n",
      "from pyspark.mllib.recommendation import ALS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_parser(names):\n",
      "    def loadRecord(line):\n",
      "        #input = StringIO.StringIO(line)\n",
      "        cells = line.strip().split('\\t')\n",
      "        return dict(zip(names, cells))\n",
      "    return loadRecord\n",
      "\n",
      "names = [\"language_code\", \"user_id\", \"user\", \"id\",\"page_title\",\"num_edits\",\"bytes_added\"]\n",
      "en_revision_histories = sc.textFile(\"/user/west1/revision_history_aggregated/en\").map(get_parser(names))\n",
      "es_revision_histories = sc.textFile(\"/user/west1/revision_history_aggregated/es\").map(get_parser(names))\n",
      "\n",
      "en_ratings = en_revision_histories.map(lambda x: (int(x['user_id']), int(x['id'][1:]), float(x['bytes_added'])))\n",
      "es_ratings = es_revision_histories.map(lambda x: (int(x['user_id']), int(x['id'][1:]), float(x['bytes_added'])))\n",
      "\n",
      "ratings = en_ratings.union(es_ratings).map(lambda r: (randint(0,9), r))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeRmse(model, data, n):\n",
      "    \"\"\"\n",
      "    Compute RMSE (Root Mean Squared Error).\n",
      "    \"\"\"\n",
      "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
      "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
      "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
      "      .values()\n",
      "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "numRatings = ratings.count()\n",
      "numUsers = ratings.values().map(lambda r: r[0]).distinct().count()\n",
      "numItems = ratings.values().map(lambda r: r[1]).distinct().count()\n",
      "\n",
      "print \"Got %d ratings from %d users on %d movies.\" % (numRatings, numUsers, numMovies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split ratings into train (60%), validation (20%), and test (20%) based on the \n",
      "# last digit of the timestamp, add myRatings to train, and cache them\n",
      "# training, validation, test are all RDDs of (userId, movieId, rating)\n",
      "\n",
      "numPartitions = 100\n",
      "\n",
      "training = ratings.filter(lambda x: x[0] < 6) \\\n",
      "  .values() \\\n",
      "  .union(myRatingsRDD) \\\n",
      "  .repartition(numPartitions) \\\n",
      "  .cache()\n",
      "\n",
      "validation = ratings.filter(lambda x: x[0] >= 6 and x[0] < 8) \\\n",
      "  .values() \\\n",
      "  .repartition(numPartitions) \\\n",
      "  .cache()\n",
      "\n",
      "test = ratings.filter(lambda x: x[0] >= 8).values().cache()\n",
      "\n",
      "numTraining = training.count()\n",
      "numValidation = validation.count()\n",
      "numTest = test.count()\n",
      "\n",
      "print \"Training: %d, validation: %d, test: %d\" % (numTraining, numValidation, numTest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train models and evaluate them on the validation set\n",
      "\n",
      "ranks = [8, 12]\n",
      "lambdas = [0.1, 10.0]\n",
      "numIters = [10, 20]\n",
      "bestModel = None\n",
      "bestValidationRmse = float(\"inf\")\n",
      "bestRank = 0\n",
      "bestLambda = -1.0\n",
      "bestNumIter = -1\n",
      "\n",
      "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
      "    model = ALS.train(training, rank, numIter, lmbda)\n",
      "    validationRmse = computeRmse(model, validation, numValidation)\n",
      "    print \"RMSE (validation) = %f for the model trained with \" % validationRmse + \\\n",
      "          \"rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter)\n",
      "    if (validationRmse < bestValidationRmse):\n",
      "        bestModel = model\n",
      "        bestValidationRmse = validationRmse\n",
      "        bestRank = rank\n",
      "        bestLambda = lmbda\n",
      "        bestNumIter = numIter\n",
      "\n",
      "testRmse = computeRmse(bestModel, test, numTest)\n",
      "\n",
      "# evaluate the best model on the test set\n",
      "print \"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
      "  + \"and numIter = %d, and its RMSE on the test set is %f.\" % (bestNumIter, testRmse)\n",
      "\n",
      "# compare the best model with a naive baseline that always returns the mean rating\n",
      "meanRating = training.union(validation).map(lambda x: x[2]).mean()\n",
      "baselineRmse = sqrt(test.map(lambda x: (meanRating - x[2]) ** 2).reduce(add) / numTest)\n",
      "improvement = (baselineRmse - testRmse) / baselineRmse * 100\n",
      "print \"The best model improves the baseline by %.2f\" % (improvement) + \"%.\"\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make personalized recommendations\n",
      "\n",
      "myRatedMovieIds = set([x[1] for x in myRatings])\n",
      "candidates = sc.parallelize([m for m in movies if m not in myRatedMovieIds])\n",
      "predictions = bestModel.predictAll(candidates.map(lambda x: (0, x))).collect()\n",
      "recommendations = sorted(predictions, key=lambda x: x[2], reverse=True)[:50]\n",
      "\n",
      "print \"Movies recommended for you:\"\n",
      "for i in xrange(len(recommendations)):\n",
      "    print (\"%2d: %s\" % (i + 1, movies[recommendations[i][1]])).encode('ascii', 'ignore')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load and parse the data\n",
      "data = sc.textFile(\"data/mllib/als/test.data\")\n",
      "ratings = data.map(lambda l: l.split(',')).map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
      "\n",
      "# Build the recommendation model using Alternating Least Squares\n",
      "rank = 10\n",
      "numIterations = 20\n",
      "model = ALS.train(ratings, rank, numIterations)\n",
      "\n",
      "# Evaluate the model on training data\n",
      "testdata = ratings.map(lambda p: (p[0], p[1]))\n",
      "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
      "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
      "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).reduce(lambda x, y: x + y) / ratesAndPreds.count()\n",
      "print(\"Mean Squared Error = \" + str(MSE))\n",
      "\n",
      "\n",
      "# Build the recommendation model using Alternating Least Squares based on implicit ratings\n",
      "model = ALS.trainImplicit(ratings, rank, numIterations, alpha=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}