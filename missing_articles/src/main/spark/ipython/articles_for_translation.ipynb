{
 "metadata": {
  "name": "",
  "signature": "sha256:e556f5ad00d7ec0b3aa9c579bd1b8092730c9cf18405d64b7f9ba96dcd5679cb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "from collections import Counter\n",
      "from pprint import pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_parser(names):\n",
      "    def loadRecord(line):\n",
      "        #input = StringIO.StringIO(line)\n",
      "        cells = line.strip().split('\\t')\n",
      "        return dict(zip(names, cells))\n",
      "    return loadRecord"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s= 'en'\n",
      "t = 'es'\n",
      "delim = '|PIPE|'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "G = nx.Graph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wd_languages = set(['en', 'de', 'es'])\n",
      "rd_languages = set(['en', 'de', 'es', 'wikidata'])\n",
      "ill_languages_from = set(['en', 'de', 'es'])\n",
      "ill_languages_to = set(['en', 'de', 'es'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = [\"id\", \"language_code\", \"article_name\"]\n",
      "wikidata_links = sc.textFile(\"/user/west1/interlanguage_links.tsv\").map(get_parser(names))\\\n",
      "                .filter(lambda x: x['language_code'] in wd_languages and x['id'].startswith('Q'))\\\n",
      "                .filter(lambda x: not x['article_name'].startswith('Category:'))\\\n",
      "                .filter(lambda x: not x['article_name'].startswith('Template:'))\\\n",
      "                .map(lambda x: ('wikidata'+ delim + x['id'], x['language_code'] + delim + x['article_name']))\n",
      "                \n",
      "G.add_edges_from(wikidata_links.collect())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ['ll_from', 'll_to', 'll_lang']\n",
      "for ill_lang in ill_languages_from:\n",
      "    ill = sc.textFile('/user/hive/warehouse/prod_tables.db/' + ill_lang + 'wiki_langlinks_joined')\\\n",
      "    .map(lambda x: x.split('\\t'))\\\n",
      "    .filter(lambda x: x[2] in ill_languages_to and len(x[1]) > 0 and len(x[0]) > 0)\\\n",
      "    .map(lambda x: (ill_lang + delim + x[0], x[2] + delim + x[1]))\n",
      "    G.add_edges_from(ill.collect())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ['rd_from', 'rd_to']\n",
      "for rd_lang in rd_languages:\n",
      "    rd = sc.textFile(\"/user/hive/warehouse/prod_tables.db/\" + rd_lang + \"wiki_redirect_joined\")\\\n",
      "    .map(lambda x: x.split('\\t'))\\\n",
      "    .map(lambda x: (rd_lang + delim + x[0], rd_lang + delim + x[1]))\n",
      "    G.add_edges_from(rd.collect())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_clustering(G, n, s, t, delim):\n",
      "    sub_g = G.subgraph(nx.node_connected_component(G,n ))\n",
      "    print (\"Nodes:\")\n",
      "    pprint(sub_g.nodes())\n",
      "    print(\"\\nEdges\")\n",
      "    pprint(sub_g.edges())\n",
      "    print(\"\\nCluster\")\n",
      "    pprint(get_merged_cluster(tumor_g, s, t, delim))\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test_clustering(G, 'wikidata|PIPE|Q1216998', s, t, delim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_merged_cluster(g, s, t, delim):\n",
      "    merged_items = set()\n",
      "    has_s = False\n",
      "    has_t = False\n",
      "    wikidata_items = set()\n",
      "    \n",
      "    for e in g.edges_iter():\n",
      "        e_dict = {}\n",
      "        l1, n1 = e[0].split(delim)\n",
      "        l2, n2 = e[1].split(delim)\n",
      "        e_dict[l1] = n1\n",
      "        e_dict[l2] = n2\n",
      "        \n",
      "        if 'wikidata' in e_dict and s in e_dict:\n",
      "            has_s = True\n",
      "            wikidata_items.add(e_dict['wikidata'])\n",
      "            merged_items.add(e)\n",
      "            \n",
      "        if 'wikidata' in e_dict and t in e_dict:\n",
      "            has_t = True\n",
      "            wikidata_items.add(e_dict['wikidata'])\n",
      "            merged_items.add(e)\n",
      "        \n",
      "    if len(wikidata_items) > 1 and has_s and has_t:\n",
      "        return merged_items, wikidata_items\n",
      "    else:\n",
      "        return None, None\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cc = nx.connected_component_subgraphs (G)\n",
      "merged_items = []\n",
      "for g in cc:\n",
      "    cluster, items = get_wikidata_item_cluster(g, s, t)\n",
      "    if cluster:\n",
      "        merged_items.append(cluster)\n",
      "        if 'Q133212' in  items:\n",
      "            print cluster, items\n",
      "            break\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(merged_items)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "573302"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_subgraph_missing_target_item(g, s, t, delim):\n",
      "    has_s = False\n",
      "    has_t = False\n",
      "    missing_items = {}\n",
      "    \n",
      "    for e in g.edges_iter():\n",
      "        e_dict = {}\n",
      "        l1, n1 = e[0].split(delim)\n",
      "        l2, n2 = e[1].split(delim)\n",
      "        e_dict[l1] = n1\n",
      "        e_dict[l2] = n2\n",
      "        \n",
      "        if 'wikidata' in e_dict and s in e_dict:\n",
      "            has_s = True\n",
      "            missing_items[e[0].split(delim)[1]] = e[1].split(delim)[1] \n",
      "            \n",
      "        if 'wikidata' in e_dict and t in e_dict:\n",
      "            has_t = True\n",
      "                \n",
      "    if has_s and not has_t:\n",
      "        return missing_items\n",
      "    else:\n",
      "        return {}\n",
      "    \n",
      "def get_missing_items(G, s, t, delim, n = 100):\n",
      "    cc = nx.connected_component_subgraphs (G)\n",
      "    missing_items = {}\n",
      "    for i, g in enumerate(cc):\n",
      "        missing_items.update(is_subgraph_missing_target_item(g, s, t, delim))\n",
      "        if i == n:\n",
      "            break\n",
      "    return missing_items\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "missing_items = get_missing_items(G, s, t, delim, n = 10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Join to pageview counts and sort \n",
      "missing_items_rdd = sc.parallelize(missing_items.items())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ['wikidata_id', 'lang', 'article_title', 'pageview_count']\n",
      "\n",
      "pageviews = sc.textFile('/user/west1/pagecounts/wikidata_only')\\\n",
      ".map(lambda x: x.split('\\t'))\\\n",
      ".filter(lambda x: x[1] == s)\\\n",
      ".map(lambda x: (x[0], int(x[3])))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "missing_items = missing_items_rdd.join(pageviews)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ranked_missing_items = missing_items.top(1000, key=lambda x: x[1][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp_dir = 'en-es'\n",
      "home_dir = '/home/ellery/'\n",
      "base_dir = os.path.join(home_dir, exp_dir)\n",
      "if not os.path.exists(base_dir):\n",
      "    os.makedirs(base_dir)\n",
      "\n",
      "exp_file = 'missing_articles.tsv'\n",
      "\n",
      "with open(os.path.join(base_dir, exp_file), 'w') as f:\n",
      "    for item_id, (item_name, n) in ranked_missing_items:\n",
      "        line = item_id + '\\t' + item_name + '\\t' + str(n) + '\\n'\n",
      "        f.write(line.encode('utf8'))\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    }
   ],
   "metadata": {}
  }
 ]
}