{
 "metadata": {
  "name": "",
  "signature": "sha256:fcddc1605c7c5239091f235929cdbcf002667ca550c48170468ca36010e96245"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Usage:\n",
      "#\n",
      "# On Remote:\n",
      "# export IPYTHON_OPTS=\"notebook --pylab inline --port 8123  --ip='*' --no-browser\"\n",
      "# pyspark --master yarn --deploy-mode client --num-executors 4 --executor-memory 10g --executor-cores 5\n",
      "#\n",
      "# On Local:\n",
      "# ssh -N bast1001.wikimedia.org -L 8123:stat1002.eqiad.wmnet:8123\n",
      "# Navigate to http://localhost:8123"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.sql import *\n",
      "from operator import add\n",
      "sqlContext = SQLContext(sc)\n",
      "import csv\n",
      "import StringIO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# map each row in a tsv to a dict\n",
      "def get_parser(names):\n",
      "    def loadRecord(line):\n",
      "        #input = StringIO.StringIO(line)\n",
      "        cells = line.strip().split('\\t')\n",
      "        return dict(zip(names, cells))\n",
      "    return loadRecord"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data files into RDDs\n",
      "\n",
      "names = [\"importance\", \"id\", \"category\", \"description\"]  \n",
      "top_articles = sc.textFile(\"top_10k_wikidata_entities.tsv\").map(get_parser(names))\n",
      "top_article_ids = top_articles.map(lambda x: x['id'])\n",
      "\n",
      "names = [\"id\", \"language_code\", \"article_name\"]\n",
      "interlanguage_links = sc.textFile(\"/user/west1/interlanguage_links.tsv\").map(get_parser(names))\n",
      "\n",
      "names = [\"language_code\", \"user_id\", \"user\", \"id\",\"page_title\",\"num_edits\",\"bytes_added\"]\n",
      "en_revision_histories = sc.textFile(\"/user/west1/revision_history_aggregated/en\").map(get_parser(names))\n",
      "names = [\"language_code\", \"user_id\", \"user\", \"id\",\"page_title\",\"num_edits\",\"bytes_added\"]\n",
      "es_revision_histories = sc.textFile(\"/user/west1/revision_history_aggregated/es\").map(get_parser(names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get set of articles that exist in english but not in Spanish\n",
      "items_in_english = interlanguage_links.filter(lambda x: x['language_code'] == 'en').map(lambda x: x['id'])\n",
      "items_in_spanish = interlanguage_links.filter(lambda x: x['language_code'] == 'es').map(lambda x: x['id'])\n",
      "english_items_missing_in_spanish = items_in_english.subtract(items_in_spanish)\n",
      "important_english_items_missing_in_spanish = english_items_missing_in_spanish.intersection(top_article_ids)\n",
      "missing_set = set(important_english_items_missing_in_spanish.collect())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "PythonRDD[22] at RDD at PythonRDD.scala:43"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lets save the missing articles for further inspection\n",
      "missing_set_details = interlanguage_links.filter(lambda x: x['language_code'] == 'en' and x['id'] in missing_set ).collect()\n",
      "import codecs\n",
      "with open('important_articles_missing_in_eswiki.tsv', 'w') as f:\n",
      "    f.write('id\\tname\\n')\n",
      "    for d in missing_set_details:\n",
      "        line = d['id'] + '\\t' + d['article_name'] + '\\n'\n",
      "        f.write(line.encode('utf8'))\n",
      "                 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sets of articles edited by each editor\n",
      "es_editor_to_items = es_revision_histories.map(lambda x: (x['user_id'], x['id'])).groupByKey()\n",
      "en_editor_to_items = en_revision_histories.map(lambda x: (x['user_id'], x['id'])).groupByKey()\n",
      "# Only consider editors with n or more edits\n",
      "n = 5\n",
      "es_editor_to_items = es_editor_to_items.filter(lambda p: len(p[1]) > n)\n",
      "en_editor_to_items = en_editor_to_items.filter(lambda p: len(p[1]) > n)\n",
      "# find english editors who edited important articles missing in spanish\n",
      "def edited_important(pair):\n",
      "    edited_items = set(pair[1])\n",
      "    return len(missing_set.intersection(edited_items)) > 0\n",
      "    \n",
      "important_missing_item_en_editor_to_items = en_editor_to_items.filter(edited_important)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print important_missing_item_en_editor_to_items.count()\n",
      "print es_editor_to_items.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "35114"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute item set overlap between spanish and english editors\n",
      "rate = 5.0\n",
      "en_sample = important_missing_item_en_editor_to_items.sample(False, 1/rate, 4232)\n",
      "es_sample = es_editor_to_items.sample(False, 1/rate, 4232)\n",
      "en_es_cartesian = en_sample.cartesian(es_sample)\n",
      "\n",
      "def compute_overlap(pair):\n",
      "    es_editor_pages = set(pair[0][1])\n",
      "    en_editor_pages = set(pair[1][1])\n",
      "    return (len(es_editor_pages.intersection(en_editor_pages)), 1)\n",
      "\n",
      "en_es_overlap_counts = en_es_cartesian.map(compute_overlap).reduceByKey(add) \n",
      "counts = en_es_overlap_counts.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save the counts for inspection\n",
      "counts.sort(key =lambda x: x[0])\n",
      "with open('es_en_overlap.tsv', 'w') as f:\n",
      "    f.write('num_overlapping_articles\\tfrequency\\n')\n",
      "    for p in counts:\n",
      "        line = str(p[0]) + '\\t' + str(p[1]) + '\\n'\n",
      "        f.write(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}